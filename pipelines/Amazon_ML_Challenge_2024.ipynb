{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AyushDhimann/Amazon-ML-Challenge-2024/blob/main/Amazon_ML_Challenge_2024.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Heating Up"
      ],
      "metadata": {
        "id": "8-EQgu0rcCnv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "0HGQylpscLX3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "# Define paths\n",
        "drive_path_train = '/content/drive/MyDrive/dataset/train.csv'\n",
        "drive_path_test = '/content/drive/MyDrive/dataset/test.csv'\n",
        "colab_path_train = '/content/train.csv'\n",
        "colab_path_test = '/content/test.csv'\n",
        "\n",
        "# Copy files to Colab working directory\n",
        "shutil.copy(drive_path_train, colab_path_train)\n",
        "shutil.copy(drive_path_test, colab_path_test)\n"
      ],
      "metadata": {
        "id": "CBSAoz65cPCI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q git+https://github.com/huggingface/transformers.git\n",
        "!pip install -q accelerate datasets peft bitsandbytes peft"
      ],
      "metadata": {
        "id": "6Z_lDxcKcQ_j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Downloading"
      ],
      "metadata": {
        "id": "j5rjJtEWdxKr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code to chunck 20 values of train for each entity_name and test aswell\n",
        "import os\n",
        "import pandas as pd\n",
        "import requests\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "from datasets import Dataset, DatasetDict\n",
        "from huggingface_hub import login\n",
        "\n",
        "# Create directories for saving images\n",
        "train_image_dir = \"/content/images/train\"\n",
        "os.makedirs(train_image_dir, exist_ok=True)\n",
        "\n",
        "test_image_dir = \"/content/images/test\"\n",
        "os.makedirs(test_image_dir, exist_ok=True)\n",
        "\n",
        "# Step 1: Load and shorten the dataset (ensure 20 images for each unique entity_name)\n",
        "def shorten_dataset(train_df, test_df, limit=100):\n",
        "    # Create 'id' columns\n",
        "    train_df['id'] = [f\"train_{i}\" for i in range(len(train_df))]\n",
        "    test_df['id'] = [f\"test_{i}\" for i in range(len(test_df))]\n",
        "\n",
        "    # Ensure 20 rows for every unique entity_name in the train dataset\n",
        "    if 'entity_name' in train_df.columns:\n",
        "        train_df_grouped = train_df.groupby('entity_name')\n",
        "        train_df_list = []\n",
        "\n",
        "        for name, group in train_df_grouped:\n",
        "            if len(group) >= 20:\n",
        "                # If there are 20 or more rows, sample 20 rows\n",
        "                sampled_group = group.sample(20, random_state=42)\n",
        "            else:\n",
        "                # If fewer than 20 rows, repeat rows to make up 20 rows\n",
        "                sampled_group = group.sample(20, replace=True, random_state=42)\n",
        "            train_df_list.append(sampled_group)\n",
        "\n",
        "        # Concatenate the list into a new dataframe\n",
        "        train_df = pd.concat(train_df_list)\n",
        "\n",
        "    # Limit the test dataset to 100 rows\n",
        "    test_df = test_df.head(limit)\n",
        "\n",
        "    # Add 'query' and 'answers' columns to the train dataset\n",
        "    if 'entity_name' in train_df.columns and 'entity_value' in train_df.columns:\n",
        "        train_df['query'] = train_df['entity_name'].apply(lambda x: f\"What is the {x}?\")\n",
        "        train_df['answers'] = train_df['entity_value']\n",
        "\n",
        "    # Add 'query' column and dummy 'answers' to the test dataset\n",
        "    if 'entity_name' in test_df.columns:\n",
        "        test_df['query'] = test_df['entity_name'].apply(lambda x: f\"What is the {x}?\")\n",
        "        test_df['answers'] = \"\"  # Add a dummy 'answers' column\n",
        "\n",
        "    # Save shortened datasets\n",
        "    train_df.to_csv(\"train_short.csv\", index=False)\n",
        "    test_df.to_csv(\"test_short.csv\", index=False)\n",
        "\n",
        "    return train_df, test_df\n",
        "\n",
        "# Step 2: Download images in batches and link them to the dataset\n",
        "def download_image(url, img_id, save_dir):\n",
        "    \"\"\"Download an image from the URL and save it locally.\"\"\"\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        img = Image.open(BytesIO(response.content))\n",
        "        img_filename = f\"{img_id}.jpg\"\n",
        "        img_path = os.path.join(save_dir, img_filename)\n",
        "        img.save(img_path)\n",
        "        return img_path\n",
        "    except Exception as e:\n",
        "        print(f\"Error downloading {url}: {e}\")\n",
        "        return None\n",
        "\n",
        "def download_images_in_batches(df, image_dir, batch_size=20):\n",
        "    \"\"\"Download images in batches and update the dataset with file paths.\"\"\"\n",
        "    for i in range(0, len(df), batch_size):\n",
        "        batch = df.iloc[i:i + batch_size]\n",
        "        print(f\"Downloading batch {i // batch_size + 1}\")\n",
        "        for index, row in batch.iterrows():\n",
        "            img_path = download_image(row['image_link'], row['id'], image_dir)\n",
        "            df.loc[index, 'image_path'] = img_path  # Use .loc to avoid SettingWithCopyWarning\n",
        "    return df\n",
        "\n",
        "# Step 3: Load CSV data\n",
        "train_csv = 'train.csv'\n",
        "test_csv = 'test.csv'\n",
        "\n",
        "train_df = pd.read_csv(train_csv, low_memory=False)\n",
        "test_df = pd.read_csv(test_csv, low_memory=False)\n",
        "\n",
        "# Step 4: Shorten the dataset (limit to 100 rows, ensure 20 per entity_name)\n",
        "train_df_short, test_df_short = shorten_dataset(train_df, test_df)\n",
        "\n",
        "# Step 5: Download images for train and test datasets\n",
        "train_df_short = download_images_in_batches(train_df_short, train_image_dir)\n",
        "test_df_short = download_images_in_batches(test_df_short, test_image_dir)\n",
        "\n",
        "# Step 6: Create Hugging Face Dataset objects\n",
        "def create_train_dataset(df):\n",
        "    if 'query' in df.columns and 'answers' in df.columns:\n",
        "        dataset_dict = {\n",
        "            'id': df['id'],\n",
        "            'image': df['image_path'],\n",
        "            'query': df['query'],\n",
        "            'answers': df['answers']\n",
        "        }\n",
        "        return Dataset.from_dict(dataset_dict)\n",
        "    else:\n",
        "        raise KeyError(\"'query' or 'answers' column not found in the train dataset\")\n",
        "\n",
        "def create_test_dataset(df):\n",
        "    if 'query' in df.columns and 'answers' in df.columns:\n",
        "        dataset_dict = {\n",
        "            'id': df['id'],\n",
        "            'image': df['image_path'],\n",
        "            'query': df['query'],\n",
        "            'answers': df['answers']  # Include the dummy 'answers' column\n",
        "        }\n",
        "        return Dataset.from_dict(dataset_dict)\n",
        "    else:\n",
        "        raise KeyError(\"'query' or 'answers' column not found in the test dataset\")\n",
        "\n",
        "# Step 7: Create DatasetDict for train and test splits\n",
        "try:\n",
        "    print(\"Creating train and test datasets for Hugging Face\")\n",
        "    train_dataset = create_train_dataset(train_df_short)\n",
        "    test_dataset = create_test_dataset(test_df_short)\n",
        "except KeyError as e:\n",
        "    print(e)\n",
        "    raise\n",
        "\n",
        "split_dataset = DatasetDict({\n",
        "    \"train\": train_dataset,\n",
        "    \"test\": test_dataset\n",
        "})\n"
      ],
      "metadata": {
        "id": "RCza9GX8d1qM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hugging Face Auth"
      ],
      "metadata": {
        "id": "0JYnFBJOcjvT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "notebook_login()\n",
        "\n",
        "# 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"
      ],
      "metadata": {
        "id": "7hbTjpx0cpsO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# train_dataset = load_dataset(\"ayushdhiman/TryTry\", split=\"train\")\n",
        "eval_dataset = load_dataset(\"ayushdhiman/TryTry\", split=\"test\")"
      ],
      "metadata": {
        "id": "twJwz6gwdEVp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import IPython.display as display\n",
        "\n",
        "# Load and display the image\n",
        "image_path = train_dataset[25]['image']\n",
        "img = Image.open(image_path)\n",
        "display.display(img)\n"
      ],
      "metadata": {
        "id": "R6F4671qdIEO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine Tuning"
      ],
      "metadata": {
        "id": "reGsrfECdIwS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from peft import LoraConfig\n",
        "from transformers import AutoProcessor, BitsAndBytesConfig, Idefics2ForConditionalGeneration\n",
        "\n",
        "DEVICE = \"cuda:0\"\n",
        "USE_LORA = False\n",
        "USE_QLORA = True\n",
        "\n",
        "processor = AutoProcessor.from_pretrained(\n",
        "    \"HuggingFaceM4/idefics2-8b\",\n",
        "    do_image_splitting=False\n",
        ")\n",
        "\n",
        "if USE_QLORA or USE_LORA:\n",
        "    lora_config = LoraConfig(\n",
        "        r=8,\n",
        "        lora_alpha=8,\n",
        "        lora_dropout=0.1,\n",
        "        target_modules='.*(text_model|modality_projection|perceiver_resampler).*(down_proj|gate_proj|up_proj|k_proj|q_proj|v_proj|o_proj).*$',\n",
        "        use_dora=False if USE_QLORA else True,\n",
        "        init_lora_weights=\"gaussian\"\n",
        "    )\n",
        "    if USE_QLORA:\n",
        "        bnb_config = BitsAndBytesConfig(\n",
        "            load_in_4bit=True,\n",
        "            bnb_4bit_quant_type=\"nf4\",\n",
        "            bnb_4bit_compute_dtype=torch.float16\n",
        "        )\n",
        "    model = Idefics2ForConditionalGeneration.from_pretrained(\n",
        "        \"HuggingFaceM4/idefics2-8b\",\n",
        "        torch_dtype=torch.float16,\n",
        "        quantization_config=bnb_config if USE_QLORA else None,\n",
        "    )\n",
        "    model.add_adapter(lora_config)\n",
        "    model.enable_adapters()\n",
        "else:\n",
        "    model = Idefics2ForConditionalGeneration.from_pretrained(\n",
        "        \"HuggingFaceM4/idefics2-8b\",\n",
        "        torch_dtype=torch.float16,\n",
        "        _attn_implementation=\"flash_attention_2\", # This works for A100 or H100\n",
        "    ).to(DEVICE)"
      ],
      "metadata": {
        "id": "p9Qijm6qdLZh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyDataCollator:\n",
        "    def __init__(self, processor):\n",
        "        self.processor = processor\n",
        "        self.image_token_id = processor.tokenizer.additional_special_tokens_ids[\n",
        "            processor.tokenizer.additional_special_tokens.index(\"<image>\")\n",
        "        ]\n",
        "\n",
        "    def __call__(self, examples):\n",
        "        texts = []\n",
        "        images = []\n",
        "        for example in examples:\n",
        "            print(f\"Processing example: {example}\")  # Debugging statement\n",
        "\n",
        "            image = example[\"image\"]\n",
        "            question = example[\"query\"]  # 'query' is treated as a string\n",
        "            answer = example[\"answers\"]  # 'answers' is treated as a string\n",
        "\n",
        "            messages = [\n",
        "                {\n",
        "                    \"role\": \"user\",\n",
        "                    \"content\": [\n",
        "                        {\"type\": \"text\", \"text\": \"Answer briefly.\"},\n",
        "                        {\"type\": \"image\"},\n",
        "                        {\"type\": \"text\", \"text\": question}\n",
        "\n",
        "                    ]\n",
        "                },\n",
        "                {\n",
        "                    \"role\": \"assistant\",\n",
        "                    \"content\": [\n",
        "                        {\"type\": \"text\", \"text\": answer}\n",
        "                    ]\n",
        "                }\n",
        "            ]\n",
        "            text = self.processor.apply_chat_template(messages, add_generation_prompt=False)\n",
        "            texts.append(text.strip())\n",
        "            images.append([image])\n",
        "\n",
        "        batch = self.processor(text=texts, images=images, return_tensors=\"pt\", padding=True)\n",
        "\n",
        "        labels = batch[\"input_ids\"].clone()\n",
        "        labels[labels == self.processor.tokenizer.pad_token_id] = self.image_token_id\n",
        "        batch[\"labels\"] = labels\n",
        "\n",
        "        return batch\n",
        "\n",
        "\n",
        "from transformers import TrainingArguments, Trainer\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir = \"IDEFICS_DocVQA_1\",\n",
        "    learning_rate = 2e-4,\n",
        "    fp16 = True,\n",
        "    per_device_train_batch_size = 2,\n",
        "    per_device_eval_batch_size = 2,\n",
        "    gradient_accumulation_steps = 8,\n",
        "    dataloader_pin_memory = False,\n",
        "    save_total_limit = 3,\n",
        "    evaluation_strategy =\"steps\",\n",
        "    save_strategy = \"steps\",\n",
        "    eval_steps = 10,\n",
        "    save_steps = 25,\n",
        "    max_steps = 25,\n",
        "    logging_steps = 5,\n",
        "    remove_unused_columns = False,\n",
        "    push_to_hub=False,\n",
        "    label_names = [\"labels\"],\n",
        "    load_best_model_at_end = False,\n",
        "    report_to = \"none\",\n",
        "    optim = \"paged_adamw_8bit\",\n",
        ")\n",
        "\n",
        "# Data collator instance\n",
        "data_collator = MyDataCollator(processor)\n",
        "\n",
        "# Trainer instance\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset\n",
        ")\n"
      ],
      "metadata": {
        "id": "Op9CmjwXdPtY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training the model"
      ],
      "metadata": {
        "id": "7u9I7HpRdetp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "ve5E5PDBdddk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prompting the model"
      ],
      "metadata": {
        "id": "fJSftIpBdlBi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "\n",
        "# Ensure that `image` is loaded as a single image, not a list or batch\n",
        "image_path = \"/content/images/test/test_11.jpg\"  # Replace with actual path\n",
        "image = Image.open(image_path)  # Load the image properly\n",
        "\n",
        "query = \"What is the depth? \"\n",
        "\n",
        "\n",
        "\n",
        "# Process the single image with the query\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": [\n",
        "            {\"type\": \"text\", \"text\": \"Answer briefly.\"},\n",
        "            {\"type\": \"image\"},  # Single image token\n",
        "            {\"type\": \"text\", \"text\": query}\n",
        "        ]\n",
        "    }\n",
        "]\n",
        "\n",
        "# Apply the chat template\n",
        "text = processor.apply_chat_template(messages, add_generation_prompt=True)\n",
        "\n",
        "# Process the inputs correctly for a single image\n",
        "inputs = processor(text=[text.strip()], images=[image], return_tensors=\"pt\", padding=True)\n",
        "\n",
        "# Generate output from the model\n",
        "generated_ids = model.generate(**inputs, max_new_tokens=64)\n",
        "\n",
        "# Decode the generated text\n",
        "generated_texts = processor.batch_decode(generated_ids[:, inputs[\"input_ids\"].size(1):], skip_special_tokens=True)\n",
        "print(generated_texts)\n"
      ],
      "metadata": {
        "id": "pAz2-P9adoSb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Final Test Preprocessing"
      ],
      "metadata": {
        "id": "8E6xJXIhmJdi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import requests\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "\n",
        "# Create a directory for saving test images\n",
        "test_image_dir = \"/content/images/test\"\n",
        "os.makedirs(test_image_dir, exist_ok=True)\n",
        "\n",
        "# Function to download an image from the URL and save it locally with sequential numbering\n",
        "def download_image(url, img_id, save_dir):\n",
        "    \"\"\"Download an image from the URL and save it locally as <img_id>.jpeg.\"\"\"\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        img = Image.open(BytesIO(response.content))\n",
        "        img_filename = f\"{img_id}.jpeg\"\n",
        "        img_path = os.path.join(save_dir, img_filename)\n",
        "        img.save(img_path)\n",
        "        return img_path\n",
        "    except Exception as e:\n",
        "        print(f\"Error downloading {url}: {e}\")\n",
        "        return None\n",
        "\n",
        "# Function to download images for the test dataset\n",
        "def download_test_images(df, image_dir):\n",
        "    \"\"\"Download images for the test dataset and update the dataframe with image paths and IDs.\"\"\"\n",
        "    img_id = 0  # Start image numbering from 1\n",
        "    for index, row in df.iterrows():\n",
        "        # Download the image and save it with a sequential filename (e.g., 1.jpeg, 2.jpeg, etc.)\n",
        "        img_path = download_image(row['image_link'], img_id, image_dir)\n",
        "        # Update the dataframe with the new image path and sequential ID\n",
        "        df.at[index, 'id'] = img_id\n",
        "        df.at[index, 'image_path'] = img_path\n",
        "        img_id += 1  # Increment the image ID for the next row\n",
        "    return df\n",
        "\n",
        "# Load the test CSV data\n",
        "test_csv = 'test.csv'\n",
        "test_df = pd.read_csv(test_csv, low_memory=False)\n",
        "\n",
        "# Keep only the first 50 rows\n",
        "test_df = test_df.head(10)\n",
        "\n",
        "# Ensure the final CSV contains only the specified columns\n",
        "columns_to_keep = ['index', 'group_id', 'entity_name', 'image_link']  # Adjust based on the original test.csv structure\n",
        "test_df = test_df[columns_to_keep]\n",
        "\n",
        "# Download images and update the test dataframe for the first 50 rows\n",
        "test_df = download_test_images(test_df, test_image_dir)\n",
        "\n",
        "# Save the final CSV file with the required columns\n",
        "test_df_final = test_df[['index', 'id', 'image_path', 'group_id', 'entity_name']]\n",
        "test_df_final.to_csv(\"test_processed.csv\", index=False)\n",
        "\n",
        "print(\"Image download and CSV processing for first 50 items complete.\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "''' for complete data  '''\n",
        "\n",
        "# import os\n",
        "# import pandas as pd\n",
        "# import requests\n",
        "# from PIL import Image\n",
        "# from io import BytesIO\n",
        "\n",
        "# # Create a directory for saving test images\n",
        "# test_image_dir = \"/content/images/test\"\n",
        "# os.makedirs(test_image_dir, exist_ok=True)\n",
        "\n",
        "# # Function to download an image from the URL and save it locally with sequential numbering\n",
        "# def download_image(url, img_id, save_dir):\n",
        "#     \"\"\"Download an image from the URL and save it locally as <img_id>.jpeg.\"\"\"\n",
        "#     try:\n",
        "#         response = requests.get(url)\n",
        "#         img = Image.open(BytesIO(response.content))\n",
        "#         img_filename = f\"{img_id}.jpeg\"\n",
        "#         img_path = os.path.join(save_dir, img_filename)\n",
        "#         img.save(img_path)\n",
        "#         return img_path\n",
        "#     except Exception as e:\n",
        "#         print(f\"Error downloading {url}: {e}\")\n",
        "#         return None\n",
        "\n",
        "# # Function to download images for the test dataset\n",
        "# def download_test_images(df, image_dir):\n",
        "#     \"\"\"Download images for the test dataset and update the dataframe with image paths and IDs.\"\"\"\n",
        "#     img_id = 1  # Start image numbering from 1\n",
        "#     for index, row in df.iterrows():\n",
        "#         # Download the image and save it with a sequential filename (e.g., 1.jpeg, 2.jpeg, etc.)\n",
        "#         img_path = download_image(row['image_link'], img_id, image_dir)\n",
        "#         # Update the dataframe with the new image path and sequential ID\n",
        "#         df.at[index, 'id'] = img_id\n",
        "#         df.at[index, 'image_path'] = img_path\n",
        "#         img_id += 1  # Increment the image ID for the next row\n",
        "#     return df\n",
        "\n",
        "# # Load the test CSV data\n",
        "# test_csv = 'test.csv'\n",
        "# test_df = pd.read_csv(test_csv, low_memory=False)\n",
        "\n",
        "# # Ensure the final CSV contains only the specified columns\n",
        "# columns_to_keep = ['index', 'group_id', 'entity_name', 'image_link']  # Adjust based on the original test.csv structure\n",
        "# test_df = test_df[columns_to_keep]\n",
        "\n",
        "# # Download images and update the test dataframe\n",
        "# test_df = download_test_images(test_df, test_image_dir)\n",
        "\n",
        "# # Save the final CSV file with the required columns\n",
        "# test_df_final = test_df[['index', 'id', 'image_path', 'group_id', 'entity_name']]\n",
        "# test_df_final.to_csv(\"test_processed.csv\", index=False)\n",
        "\n",
        "# print(\"Image download and CSV processing complete.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "12p0PX0DmRzE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "# Output Pipeline"
      ],
      "metadata": {
        "id": "VRjoUv_imhy0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "\n",
        "# Load the CSV file containing image paths and entity names\n",
        "csv_path = \"test_processed.csv\"\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "# Function to process the images and generate output from the model\n",
        "def process_images_and_generate_output(df, processor, model, output_csv=\"output.csv\"):\n",
        "    results = []\n",
        "\n",
        "    for index, row in df.iterrows():\n",
        "        image_path = row['image_path']\n",
        "        entity = row['entity_name']\n",
        "        img_id = row['index']\n",
        "\n",
        "        # Load the image\n",
        "        try:\n",
        "            image = Image.open(image_path)\n",
        "\n",
        "            # Dynamically create the query with the entity name\n",
        "            query = f\"What is the {entity} ?\"\n",
        "\n",
        "            # Prepare the message with the query and image\n",
        "            messages = [\n",
        "                {\n",
        "                    \"role\": \"user\",\n",
        "                    \"content\": [\n",
        "                        {\"type\": \"text\", \"text\": \" Answer Briefly \"},\n",
        "                        {\"type\": \"image\"},\n",
        "                        {\"type\": \"text\", \"text\": query}\n",
        "                    ]\n",
        "                }\n",
        "            ]\n",
        "\n",
        "            # Apply the chat template\n",
        "            text = processor.apply_chat_template(messages, add_generation_prompt=True)\n",
        "\n",
        "            # Process the inputs for a single image and query\n",
        "            inputs = processor(text=[text.strip()], images=[image], return_tensors=\"pt\", padding=True)\n",
        "\n",
        "            # Generate the model output\n",
        "            generated_ids = model.generate(**inputs, max_new_tokens=64)\n",
        "\n",
        "            # Decode the generated text\n",
        "            generated_texts = processor.batch_decode(generated_ids[:, inputs[\"input_ids\"].size(1):], skip_special_tokens=True)\n",
        "            generated_text = generated_texts[0].strip()\n",
        "\n",
        "            # Save the result as (id, generated_text)\n",
        "            results.append({\"index\": img_id, \"prediction\": generated_text})\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing image {image_path}: {e}\")\n",
        "            results.append({\"index\": img_id, \"prediction\": \"\"})  # Save empty result for error cases\n",
        "\n",
        "    # Save the results to a new CSV file\n",
        "    output_df = pd.DataFrame(results)\n",
        "    output_df.to_csv(output_csv, index=False)\n",
        "    print(f\"Output saved to {output_csv}\")\n",
        "\n",
        "# Example call (assuming you have defined `processor` and `model` already)\n",
        "process_images_and_generate_output(df, processor, model, output_csv=\"final_output.csv\")\n"
      ],
      "metadata": {
        "id": "CnMDPearmWDR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Parallel Pipeline"
      ],
      "metadata": {
        "id": "jTDF6vT_QJTr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "import torch\n",
        "\n",
        "# Function to load and process a single image\n",
        "def process_single_image(image_path, entity, img_id, processor, model):\n",
        "    try:\n",
        "        # Load the image\n",
        "        image = Image.open(image_path)\n",
        "\n",
        "        # Dynamically create the query with the entity name\n",
        "        query = f\"What is the {entity}?\"\n",
        "\n",
        "        # Prepare the message with the query and image\n",
        "        messages = [\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": [\n",
        "                    {\"type\": \"text\", \"text\": \" Answer Briefly \"},\n",
        "                    {\"type\": \"image\"},\n",
        "                    {\"type\": \"text\", \"text\": query}\n",
        "                ]\n",
        "            }\n",
        "        ]\n",
        "\n",
        "        # Apply the chat template\n",
        "        text = processor.apply_chat_template(messages, add_generation_prompt=True)\n",
        "\n",
        "        # Process the inputs for a single image and query\n",
        "        inputs = processor(text=[text.strip()], images=[image], return_tensors=\"pt\", padding=True)\n",
        "\n",
        "        # Generate the model output\n",
        "        with torch.no_grad():  # Ensure no gradients are calculated\n",
        "            generated_ids = model.generate(**inputs, max_new_tokens=64)\n",
        "\n",
        "        # Decode the generated text\n",
        "        generated_texts = processor.batch_decode(generated_ids[:, inputs[\"input_ids\"].size(1):], skip_special_tokens=True)\n",
        "        generated_text = generated_texts[0].strip()\n",
        "\n",
        "        # Return the result as (id, generated_text)\n",
        "        return {\"index\": img_id, \"prediction\": generated_text}\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing image {image_path}: {e}\")\n",
        "        return {\"index\": img_id, \"prediction\": \"\"}  # Save empty result for error cases\n",
        "\n",
        "# Batch processing and parallelization\n",
        "def process_images_and_generate_output(df, processor, model, output_csv=\"output.csv\", num_threads=8):\n",
        "    results = []\n",
        "\n",
        "    # Use a ThreadPoolExecutor to process images in parallel\n",
        "    with ThreadPoolExecutor(max_workers=num_threads) as executor:\n",
        "        future_to_row = {\n",
        "            executor.submit(\n",
        "                process_single_image, row['image_path'], row['entity_name'], row['index'], processor, model\n",
        "            ): row for _, row in df.iterrows()\n",
        "        }\n",
        "\n",
        "        # Collect results as they are completed\n",
        "        for future in as_completed(future_to_row):\n",
        "            result = future.result()\n",
        "            results.append(result)\n",
        "\n",
        "    # Save the results to a new CSV file\n",
        "    output_df = pd.DataFrame(results)\n",
        "    output_df.to_csv(output_csv, index=False)\n",
        "    print(f\"Output saved to {output_csv}\")\n",
        "\n",
        "# Example call (assuming you have defined `processor` and `model` already)\n",
        "\n",
        "\n",
        "# Load the CSV file containing image paths and entity names\n",
        "csv_path = \"test_processed.csv\"  # Ensure the path is correct\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "\n",
        "\n",
        "process_images_and_generate_output(df, processor, model, output_csv=\"final_output.csv\", num_threads=12)"
      ],
      "metadata": {
        "id": "_UKFTAlfQIhv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}